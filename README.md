# Quart

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8%2B-green.svg)](https://www.python.org/)

## ğŸ¯ Key Features

- **Pipeline-Aware Resource Management**: Dynamically identifies and scales critical pipeline stages using CV-based burst propagation analysis
- **PID-Controlled Replica Allocation**: Automatically adjusts replicas for congested stages using queuing theory and feedback control
- **CV-Based Pipeline Smoothing**: Optimizes resource distribution across pipeline stages through Graph Attention Networks
- **Adaptive CPU Compensation**: Dynamically allocates CPU resources when GPU replicas are consolidated
- **Hierarchical Parameter Caching**: Enables sub-second scaling through copy-on-write memory caching (KeysManager)
- **Cache-Aware Scheduling**: Optimizes stage placement using KL divergence for maximum cache utilization


## ğŸ—ï¸ System Architecture

Quart consists of four coordinated components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Quart System                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Replica      â”‚  â”‚  Pipeline    â”‚  â”‚      CPU      â”‚  â”‚
â”‚  â”‚  Corrector     â”‚â†’ â”‚  Smoother    â”‚â†’ â”‚  Compensator  â”‚  â”‚
â”‚  â”‚  (PID+M/M/c)   â”‚  â”‚  (GAT+CV)    â”‚  â”‚  (Adaptive)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â†“                                â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚                   â”‚  Cache-Aware    â”‚                       â”‚
â”‚                   â”‚   Scheduler     â”‚                       â”‚
â”‚                   â”‚ (KeysManager+KL)â”‚                       â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Details

1. **Replica Corrector** (`OCD/ReplicaCorrector.py`)
   - M/M/c queuing model for stage delay prediction
   - PID controller for dynamic replica adjustment
   - Critical stage identification based on queue depth

2. **Pipeline Smoother** (`OCD/PipelineSmoother.py`)
   - Graph Attention Network for CV propagation modeling
   - Adaptive smoothing strategy based on predicted burstiness
   - Resource reallocation from over-provisioned to critical stages

3. **CPU Compensator** (`OCD/CPUCompensator.py`)
   - Multi-factor CPU demand prediction model
   - Incremental allocation with performance monitoring
   - cgroup-based bandwidth control

4. **Cache-Aware Scheduler** (`OCD/CacheAwareScheduler.py`)
   - KeysManager for hierarchical parameter caching
   - KL divergence optimization for dispersed placement
   - Copy-on-write fork mechanisms for sub-second scaling

## ğŸš€ Quick Start

### Prerequisites

- **Cluster**: 12+ GPU servers (A40/V100/3090 or similar)
- **Kubernetes**: v1.24 or higher
- **OpenFaaS**: Latest version with faasd
- **Python**: 3.8+
- **Dependencies**: PyTorch, Kubernetes Python client, Prometheus API client

### Installation

1. Clone the repository:
```bash
git clone https://github.com/your-org/quart.git
cd quart
```

2. Install Python dependencies:
```bash
pip install -r requirements.txt
```

3. Configure Kubernetes access:
```bash
export KUBECONFIG=/path/to/kubeconfig
kubectl cluster-info
```

4. Deploy Prometheus for metrics:

5. Set up OpenFaaS:
```bash
# Follow OpenFaaS installation guide
# Deploy gateway and configure namespaces
```

### Basic Usage

1. **Deploy Model Pipeline**:
```bash
cd benchmark/BERT/ME-21
./action_deploy.sh
```

2. **Start Replica Corrector**:
```bash
cd OCD
python DaShengScaler.py
```

3. **Start Cache-Aware Scheduler**:
```bash
cd OCD
python DaShengScheduler.py
```

4. **Monitor System**:
```bash
# Access Prometheus dashboard
kubectl port-forward -n monitoring svc/prometheus 9090:9090

# View scheduler logs
tail -f OCD/scheduler_record.csv
```


## ğŸ“ Project Structure

```
quart/
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ OCD/                           # Core implementation
â”‚   â”œâ”€â”€ ReplicaCorrector.py        # PID-based replica correction
â”‚   â”œâ”€â”€ PipelineSmoother.py        # CV-based pipeline smoothing
â”‚   â”œâ”€â”€ CPUCompensator.py          # Adaptive CPU compensation
â”‚   â”œâ”€â”€ CacheAwareScheduler.py     # Cache-aware scheduling
â”‚   â”œâ”€â”€ DaShengScaler.py           # Main scaler (legacy + integration)
â”‚   â”œâ”€â”€ DaShengScheduler.py        # Main scheduler (legacy + integration)
â”‚   â”œâ”€â”€ Metrics.py                 # Prometheus metrics collector
â”‚   â”œâ”€â”€ perfering.py               # GPU/CPU metrics
â”‚   â””â”€â”€ hook/                      # Kubernetes webhook configs
â”œâ”€â”€ benchmark/                     # Model deployment configurations
â”‚   â”œâ”€â”€ BERT/                      # BERT-21B pipeline configurations
â”‚   â”œâ”€â”€ LLAMA/                     # LLAMA-7B configurations
â”‚   â”œâ”€â”€ GPT/                       # OPT-66B configurations
â”‚   â”œâ”€â”€ WHISPER/                   # Whisper-9B configurations
â”‚   â””â”€â”€ function_template/         # OpenFaaS templates
```


## ğŸ“ˆ Performance Tuning

### PID Controller Tuning

Adjust gains in `ReplicaCorrector.py`:
```python
corrector = ReplicaCorrector(
    prometheus,
    kp=2.0,  # Proportional gain (responsiveness)
    ki=0.3,  # Integral gain (steady-state error)
    kd=0.1   # Derivative gain (damping)
)
```

### Cache Memory Threshold

Configure in `CacheAwareScheduler.py`:
```python
keys_manager = KeysManager(
    memory_threshold=0.65  # Use up to 85% of server memory
)
```

### CPU Compensation Parameters

Tune in `CPUCompensator.py`:
```python
compensator = CPUCompensator(
    prometheus,
    min_cpu=1.0,
    max_cpu=16.0,
    increment_ratio=0.25  # Allocate 25% of predicted at a time
)
```

## ğŸ› Troubleshooting

### Common Issues

1. **High latency despite scaling**:
   - Check PID gains (may be too conservative)
   - Verify target_latency is appropriate for your SLO
   - Ensure network bandwidth is sufficient for inter-stage communication

2. **Cache misses**:
   - Increase memory_threshold in KeysManager
   - Check server memory capacity
   - Verify COW fork is working correctly

3. **Uneven stage distribution**:
   - Reduce KL divergence learning_rate for slower convergence
   - Check server capacity constraints
   - Ensure critical stages are properly identified

### Debug Mode

Enable detailed logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

View Prometheus metrics:
```bash
# Check stage metrics
curl "http://prometheus:9090/api/v1/query?query=gateway_function_invocation_started"

# Check GPU utilization
curl "http://prometheus:9090/api/v1/query?query=DCGM_FI_DEV_GPU_UTIL"
```

## ğŸ“ Citation

If you use Quart in your research, please cite our paper:

```bibtex
@inproceedings{lin2024quart,
  title = {Quart: Latency-Aware FaaS System for Pipelining Large Model Inference},
  author = {Lin, Yanying and Li, Yanbo and Peng, Shijie and Tang, Yingfei and Luo, Shutian and Shen, Haiying and Xu, Chengzhong and Ye, Kejiang},
  booktitle = {Proceedings of the 44th IEEE International Conference on Distributed Computing Systems},
  year = {2024},
}
```

## ğŸ¤ Contributing

We welcome contributions! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes with tests
4. Submit a pull request

See `CONTRIBUTING.md` for detailed guidelines.

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

We thank the open-source community for:
- Kubernetes and OpenFaaS for serverless infrastructure
- PyTorch for deep learning framework
- Prometheus for monitoring and metrics